#!/usr/bin/env python3
"""
========================================
ê³µì‹ ì´ë¯¸ì§€ ìƒì„± ìŠ¤í¬ë¦½íŠ¸ (v1.0)
========================================

âš ï¸ ì¤‘ìš”: ì´ ìŠ¤í¬ë¦½íŠ¸ë§Œ ì‚¬ìš©í•  ê²ƒ!
- ë‹¤ë¥¸ ì´ë¯¸ì§€ ìƒì„± ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš© ê¸ˆì§€
- ëª¨ë¸ ID ë³€ê²½ ê¸ˆì§€

ëª¨ë¸: fal-ai/flux-2-pro (FLUX 2.0 Pro)
í¬ê¸°: 1080x1080
ì‘ì„±: ê¹€ì˜í˜„ ê³¼ì¥
ìŠ¹ì¸: ê¹€ë¶€ì¥ (2026-01-29)
"""

import os
import asyncio
import httpx
from pathlib import Path
from dotenv import load_dotenv
from PIL import Image
import io
import json
from datetime import datetime

# ============================================
# ğŸ”’ í•˜ë“œì½”ë”© ì„¤ì • - ì ˆëŒ€ ìˆ˜ì • ê¸ˆì§€
# ============================================
MODEL_ID = "fal-ai/flux-2-pro"  # FLUX 2.0 Pro - ë³€ê²½ ê¸ˆì§€!
IMAGE_SIZE = {"width": 1080, "height": 1080}
# ============================================

# .env ë¡œë“œ
ROOT = Path(__file__).parent.parent.parent
load_dotenv(ROOT / ".env")

FAL_KEY = os.getenv("FAL_KEY")
if FAL_KEY:
    os.environ["FAL_KEY"] = FAL_KEY

import fal_client


def verify_model_id():
    """ëª¨ë¸ ID ê²€ì¦ - ë³€ì¡° ë°©ì§€"""
    if MODEL_ID != "fal-ai/flux-2-pro":
        raise RuntimeError("â›” ëª¨ë¸ IDê°€ ë³€ì¡°ë˜ì—ˆìŠµë‹ˆë‹¤! fal-ai/flux-2-proë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    return True


async def generate_image(prompt: str, output_path: Path, verbose: bool = True) -> dict:
    """
    fal.ai FLUX 2.0 Proë¡œ ì´ë¯¸ì§€ ìƒì„±

    Args:
        prompt: ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸
        output_path: ì €ì¥ ê²½ë¡œ
        verbose: ìƒì„¸ ì¶œë ¥ ì—¬ë¶€

    Returns:
        dict: {"success": bool, "path": str, "model": str, "error": str|None}
    """
    # ëª¨ë¸ ID ê²€ì¦
    verify_model_id()

    if verbose:
        print(f"  ğŸ“¸ ìƒì„± ì¤‘: {output_path.name}")
        print(f"  ğŸ¤– ëª¨ë¸: {MODEL_ID}")
        print(f"  ğŸ“ í”„ë¡¬í”„íŠ¸: {prompt[:60]}...")

    try:
        # fal.ai FLUX 2.0 Pro í˜¸ì¶œ
        result = await asyncio.to_thread(
            fal_client.subscribe,
            MODEL_ID,  # í•˜ë“œì½”ë”©ëœ ëª¨ë¸ ID ì‚¬ìš©
            arguments={
                "prompt": prompt,
                "image_size": IMAGE_SIZE,
                "num_images": 1,
                "output_format": "png",
                "safety_tolerance": "5",
            }
        )

        # ì´ë¯¸ì§€ URL ì¶”ì¶œ
        image_url = result["images"][0]["url"]

        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        async with httpx.AsyncClient(timeout=60.0) as client:
            response = await client.get(image_url)
            response.raise_for_status()

            # PILë¡œ ì´ë¯¸ì§€ ì²˜ë¦¬ ë° ì €ì¥
            img = Image.open(io.BytesIO(response.content))
            if img.size != (IMAGE_SIZE["width"], IMAGE_SIZE["height"]):
                img = img.resize(
                    (IMAGE_SIZE["width"], IMAGE_SIZE["height"]),
                    Image.Resampling.LANCZOS
                )

            # í´ë” ìƒì„±
            output_path.parent.mkdir(parents=True, exist_ok=True)
            img.save(output_path, "PNG", optimize=True)

        if verbose:
            print(f"  âœ… ì™„ë£Œ: {output_path}")

        return {
            "success": True,
            "path": str(output_path),
            "model": MODEL_ID,
            "error": None
        }

    except Exception as e:
        error_msg = f"{type(e).__name__}: {e}"
        if verbose:
            print(f"  âŒ ì‹¤íŒ¨: {error_msg}")
        return {
            "success": False,
            "path": str(output_path),
            "model": MODEL_ID,
            "error": error_msg
        }


async def generate_batch(prompts: list[dict], output_dir: Path, prefix: str = "image") -> list[dict]:
    """
    ì—¬ëŸ¬ ì´ë¯¸ì§€ ì¼ê´„ ìƒì„±

    Args:
        prompts: [{"filename": "xxx.png", "prompt": "..."}, ...]
        output_dir: ì¶œë ¥ í´ë”
        prefix: íŒŒì¼ëª… ì ‘ë‘ì‚¬ (filename ì—†ì„ ë•Œ ì‚¬ìš©)

    Returns:
        list[dict]: ê° ì´ë¯¸ì§€ ìƒì„± ê²°ê³¼
    """
    verify_model_id()

    print("=" * 60)
    print(f"ğŸ¨ ì´ë¯¸ì§€ ì¼ê´„ ìƒì„±")
    print(f"ğŸ¤– ëª¨ë¸: {MODEL_ID} (FLUX 2.0 Pro)")
    print(f"ğŸ“ ì¶œë ¥: {output_dir}")
    print(f"ğŸ“‹ ê°œìˆ˜: {len(prompts)}ì¥")
    print("=" * 60)

    results = []

    for i, item in enumerate(prompts):
        filename = item.get("filename", f"{prefix}_{i:02d}.png")
        prompt = item.get("prompt", "")

        if not prompt:
            print(f"  âš ï¸ ìŠ¤í‚µ: {filename} (í”„ë¡¬í”„íŠ¸ ì—†ìŒ)")
            continue

        output_path = output_dir / filename

        # ì´ë¯¸ ì¡´ì¬í•˜ë©´ ìŠ¤í‚µ
        if output_path.exists():
            print(f"  â­ï¸ ìŠ¤í‚µ: {filename} (ì´ë¯¸ ì¡´ì¬)")
            results.append({
                "success": True,
                "path": str(output_path),
                "model": MODEL_ID,
                "error": None,
                "skipped": True
            })
            continue

        result = await generate_image(prompt, output_path)
        results.append(result)

        # API ë¶€í•˜ ë°©ì§€
        if i < len(prompts) - 1:
            await asyncio.sleep(2)

    # ê²°ê³¼ ìš”ì•½
    success_count = sum(1 for r in results if r.get("success"))
    print("\n" + "=" * 60)
    print(f"âœ¨ ì™„ë£Œ: {success_count}/{len(prompts)}ê°œ ì„±ê³µ")
    print(f"ğŸ¤– ì‚¬ìš© ëª¨ë¸: {MODEL_ID}")
    print("=" * 60)

    return results


def get_model_info() -> dict:
    """í˜„ì¬ ì„¤ì •ëœ ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
    return {
        "model_id": MODEL_ID,
        "model_name": "FLUX 2.0 Pro",
        "image_size": IMAGE_SIZE,
        "verified": verify_model_id()
    }


# CLI ì‹¤í–‰
if __name__ == "__main__":
    import sys

    print("=" * 60)
    print("ğŸ”’ ê³µì‹ ì´ë¯¸ì§€ ìƒì„± ìŠ¤í¬ë¦½íŠ¸")
    print(f"ğŸ¤– ëª¨ë¸: {MODEL_ID} (ë³€ê²½ ë¶ˆê°€)")
    print("=" * 60)

    if len(sys.argv) < 3:
        print("\nì‚¬ìš©ë²•:")
        print("  python generate_images.py <output_path> <prompt>")
        print("\nì˜ˆì‹œ:")
        print('  python generate_images.py ./test.png "A golden retriever"')
        sys.exit(1)

    output = Path(sys.argv[1])
    prompt = sys.argv[2]

    asyncio.run(generate_image(prompt, output))
