#!/usr/bin/env python3
"""
distribute_clean_images.py - í´ë¦° ì´ë¯¸ì§€ ë°°ì¹˜ ìŠ¤í¬ë¦½íŠ¸
99_CleanReady/ â†’ ê° ì½˜í…ì¸  0_clean/ ë³µì‚¬ + ë…¸ì…˜ ì—…ë°ì´íŠ¸

Â§17 í´ë¦° ì´ë¯¸ì§€ ê´€ë¦¬ ê·œì¹™ ì¤€ìˆ˜:
- âœ… ë³µì‚¬ (cp) ë§Œ í—ˆìš©
- âŒ ì´ë™ (mv) ê¸ˆì§€
- 99_CleanReady = ì›ë³¸ ë°±ì—… (ì ˆëŒ€ ì‚­ì œ ê¸ˆì§€)

ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€:
- _done/ í´ë”ë¡œ ì²˜ë¦¬ ì™„ë£Œ íŒŒì¼ ì´ë™ (99ì—ì„œë§Œ ì´ë™ í—ˆìš©)
- _processed.logë¡œ ì²˜ë¦¬ ì´ë ¥ ê´€ë¦¬
"""

import os
import shutil
import requests
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv

PROJECT_ROOT = Path(__file__).parent.parent
load_dotenv(PROJECT_ROOT / ".env")

NOTION_API_KEY = os.getenv("NOTION_API_KEY")
NOTION_DATABASE_ID = os.getenv("NOTION_DATABASE_ID")

CONTENTS_DIR = PROJECT_ROOT / "01_contents"
CLEAN_READY_DIR = CONTENTS_DIR / "99_CleanReady"
DONE_DIR = CLEAN_READY_DIR / "_done"
LOG_FILE = CLEAN_READY_DIR / "_processed.log"
# 2026-02-13: í”Œë« êµ¬ì¡°ë¡œ ë³€ê²½ - STATUS_DIRS ì œê±°
# ì´ì œ contents/ ì§ì ‘ ìŠ¤ìº”


def load_processed_list() -> set:
    """ì²˜ë¦¬ëœ íŒŒì¼ ëª©ë¡ ë¡œë“œ"""
    if not LOG_FILE.exists():
        return set()
    with open(LOG_FILE, "r", encoding="utf-8") as f:
        return set(line.strip() for line in f if line.strip())


def append_to_log(filename: str, num: int, korean: str):
    """ì²˜ë¦¬ ê¸°ë¡ ì¶”ê°€"""
    with open(LOG_FILE, "a", encoding="utf-8") as f:
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M")
        f.write(f"{filename}\t#{num:03d}\t{korean}\t{timestamp}\n")


def get_notion_headers():
    return {
        "Authorization": f"Bearer {NOTION_API_KEY}",
        "Content-Type": "application/json",
        "Notion-Version": "2022-06-28"
    }


def fetch_notion_mapping():
    """ë…¸ì…˜ì—ì„œ ìŒì‹ëª… â†’ ë²ˆí˜¸/page_id ë§¤í•‘ ìƒì„±"""
    pages = []
    has_more = True
    start_cursor = None

    while has_more:
        url = f"https://api.notion.com/v1/databases/{NOTION_DATABASE_ID}/query"
        body = {}
        if start_cursor:
            body["start_cursor"] = start_cursor

        response = requests.post(url, headers=get_notion_headers(), json=body)
        data = response.json()
        pages.extend(data.get("results", []))
        has_more = data.get("has_more", False)
        start_cursor = data.get("next_cursor")

    mapping = {}

    for page in pages:
        props = page.get("properties", {})
        num = props.get("ë²ˆí˜¸", {}).get("number")
        if num is None:
            continue

        title_arr = props.get("ì´ë¦„", {}).get("title", [])
        name = title_arr[0].get("plain_text", "").lower() if title_arr else ""

        korean_arr = props.get("í•œê¸€ëª…", {}).get("rich_text", [])
        korean = korean_arr[0].get("plain_text", "") if korean_arr else ""

        mapping[num] = {
            "name": name,
            "korean": korean,
            "page_id": page["id"]
        }

        # ì—­ë°©í–¥ ë§¤í•‘ (ì´ë¦„ â†’ ë²ˆí˜¸)
        if name:
            mapping[name] = num
            mapping[name.replace("_", "")] = num
        if korean:
            mapping[korean] = num

    return mapping


def find_content_folder(num: int) -> Path:
    """ë²ˆí˜¸ë¡œ ì½˜í…ì¸  í´ë” ì°¾ê¸° (í”Œë« êµ¬ì¡°)"""
    num_str = f"{num:03d}"
    # 2026-02-13: contents/ ì§ì ‘ ìŠ¤ìº” (í”Œë« êµ¬ì¡°)
    for item in CONTENTS_DIR.iterdir():
        if item.is_dir() and item.name.startswith(num_str):
            return item
    return None


def find_content_by_keyword(keyword: str) -> tuple:
    """í‚¤ì›Œë“œë¡œ ì½˜í…ì¸  í´ë” ì°¾ê¸° (í”Œë« êµ¬ì¡°)"""
    keyword = keyword.lower().strip()

    # 2026-02-13: contents/ ì§ì ‘ ìŠ¤ìº” (í”Œë« êµ¬ì¡°)
    for item in CONTENTS_DIR.iterdir():
        if not item.is_dir():
            continue
        folder_name = item.name.lower()
        # í´ë”ëª…ì— í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ í™•ì¸
        if keyword in folder_name:
            try:
                num = int(item.name[:3])
                return item, num
            except ValueError:
                continue
    return None, None


def update_notion_clean_status(num: int, has_clean: bool, mapping: dict):
    """ë…¸ì…˜ í‘œì§€_Clean ì—´ ì—…ë°ì´íŠ¸"""
    info = mapping.get(num)
    if not info or not isinstance(info, dict):
        return False

    page_id = info.get("page_id")
    if not page_id:
        return False

    url = f"https://api.notion.com/v1/pages/{page_id}"
    payload = {
        "properties": {
            "í‘œì§€_Clean": {"select": {"name": "ì™„ë£Œ"} if has_clean else None}
        }
    }

    response = requests.patch(url, headers=get_notion_headers(), json=payload)
    return response.status_code == 200


def distribute_clean_images(image_mapping: dict = None, dry_run: bool = False):
    """
    í´ë¦° ì´ë¯¸ì§€ ë°°ì¹˜ ì‹¤í–‰

    image_mapping: {íŒŒì¼ëª…: ì½˜í…ì¸ ë²ˆí˜¸} ë”•ì…”ë„ˆë¦¬ (ìˆ˜ë™ ë§¤í•‘ìš©)
    """
    print("â”" * 60)
    print("ğŸ“· í´ë¦° ì´ë¯¸ì§€ ë°°ì¹˜")
    print(f"   {datetime.now().strftime('%Y-%m-%d %H:%M')}")
    print("   Â§17 ê·œì¹™: ë³µì‚¬ë§Œ í—ˆìš©, ì›ë³¸ ìœ ì§€")
    print("   ì¤‘ë³µ ë°©ì§€: _done/ + _processed.log")
    print("â”" * 60)

    if not CLEAN_READY_DIR.exists():
        print(f"âŒ í´ë” ì—†ìŒ: {CLEAN_READY_DIR}")
        return

    # _done í´ë” ìƒì„±
    if not dry_run:
        DONE_DIR.mkdir(exist_ok=True)

    # ì²˜ë¦¬ëœ íŒŒì¼ ëª©ë¡ ë¡œë“œ
    processed = load_processed_list()
    print(f"\nğŸ“‹ ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼: {len(processed)}ê°œ")

    # ë…¸ì…˜ ë§¤í•‘ ë¡œë“œ
    print("ğŸ“¥ ë…¸ì…˜ ë§¤í•‘ ë¡œë“œ ì¤‘...")
    notion_mapping = fetch_notion_mapping()
    print(f"   {len([k for k in notion_mapping.keys() if isinstance(k, int)])}ê°œ ì½˜í…ì¸ ")

    # ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ (ì‹œìŠ¤í…œ íŒŒì¼ ì œì™¸)
    images = [f for f in CLEAN_READY_DIR.iterdir()
              if f.is_file()
              and not f.name.startswith("_")
              and f.suffix.lower() in [".png", ".jpg", ".jpeg", ".webp"]]

    print(f"\nğŸ“ 99_CleanReady/ ì´ë¯¸ì§€: {len(images)}ê°œ")

    stats = {
        "copied": [],
        "skipped": [],
        "already_processed": [],
        "not_found": [],
        "notion_updated": []
    }

    for img in images:
        filename = img.name

        # ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼ ìŠ¤í‚µ
        if filename in processed:
            stats["already_processed"].append(filename)
            continue

        # ë§¤í•‘ì—ì„œ ë²ˆí˜¸ ì°¾ê¸°
        num = None
        if image_mapping and filename in image_mapping:
            num = image_mapping[filename]
        else:
            # íŒŒì¼ëª… ì²« ë‹¨ì–´ë¡œ ìë™ ë§¤ì¹­ ì‹œë„
            keyword = filename.split("_")[0].lower()
            if keyword in notion_mapping and isinstance(notion_mapping[keyword], int):
                num = notion_mapping[keyword]
            else:
                # í´ë”ëª… ê²€ìƒ‰
                folder, found_num = find_content_by_keyword(keyword)
                if folder:
                    num = found_num

        if num is None:
            stats["not_found"].append(filename)
            continue

        # ì½˜í…ì¸  í´ë” ì°¾ê¸°
        content_folder = find_content_folder(num)
        if not content_folder:
            stats["not_found"].append(f"{filename} (#{num:03d} í´ë” ì—†ìŒ)")
            continue

        # 00_Clean í´ë” ìƒì„± (2026-02-13: ìƒˆ êµ¬ì¡°)
        clean_folder = content_folder / "00_Clean"

        if not dry_run:
            clean_folder.mkdir(exist_ok=True)

        # ëŒ€ìƒ íŒŒì¼ ê²½ë¡œ
        dest_path = clean_folder / filename

        # ì´ë¯¸ ì¡´ì¬í•˜ë©´ ìŠ¤í‚µ
        if dest_path.exists():
            stats["skipped"].append(f"#{num:03d} {filename}")
            continue

        # ë³µì‚¬ (ì´ë™ ì•„ë‹˜!)
        if not dry_run:
            shutil.copy2(img, dest_path)

        info = notion_mapping.get(num, {})
        korean = info.get("korean", "") if isinstance(info, dict) else ""
        print(f"   âœ… #{num:03d} {korean} â† {filename}")
        stats["copied"].append(f"#{num:03d} {korean}")

        # ë…¸ì…˜ ì—…ë°ì´íŠ¸
        if not dry_run:
            if update_notion_clean_status(num, True, notion_mapping):
                stats["notion_updated"].append(num)

        # ì²˜ë¦¬ ì™„ë£Œ: _done/ìœ¼ë¡œ ì´ë™ + ë¡œê·¸ ê¸°ë¡
        if not dry_run:
            done_path = DONE_DIR / filename
            shutil.move(str(img), str(done_path))
            append_to_log(filename, num, korean)

    # ê²°ê³¼ ë¦¬í¬íŠ¸
    print("\n" + "â”" * 60)
    print("ğŸ“Š ë°°ì¹˜ ê²°ê³¼")
    print("â”" * 60)
    print(f"âœ… ë³µì‚¬ ì™„ë£Œ: {len(stats['copied'])}ê°œ â†’ _done/ ì´ë™")
    print(f"â­ï¸ ìŠ¤í‚µ (ëŒ€ìƒ í´ë”ì— ì¡´ì¬): {len(stats['skipped'])}ê°œ")
    print(f"ğŸ”„ ìŠ¤í‚µ (ì´ë¯¸ ì²˜ë¦¬ë¨): {len(stats['already_processed'])}ê°œ")
    print(f"âŒ ë§¤ì¹­ ì‹¤íŒ¨: {len(stats['not_found'])}ê°œ")
    print(f"ğŸ“‹ ë…¸ì…˜ ì—…ë°ì´íŠ¸: {len(stats['notion_updated'])}ê°œ")

    if stats["not_found"]:
        print("\nâš ï¸ ë§¤ì¹­ ì‹¤íŒ¨ íŒŒì¼:")
        for f in stats["not_found"]:
            print(f"   - {f}")

    print("â”" * 60)

    return stats


def main():
    import sys

    dry_run = "--dry-run" in sys.argv

    if dry_run:
        print("ğŸ” DRY RUN ëª¨ë“œ (ì‹¤ì œ ë³µì‚¬ ì•ˆ í•¨)\n")

    # ìˆ˜ë™ ë§¤í•‘ì´ í•„ìš”í•œ ê²½ìš° ì—¬ê¸°ì— ì¶”ê°€
    # íŒŒì¼ëª…ì— ìŒì‹ëª…ì´ ì—†ëŠ” Higgsfield íŒŒì¼ìš©
    manual_mapping = {}

    distribute_clean_images(manual_mapping, dry_run)


if __name__ == "__main__":
    main()
