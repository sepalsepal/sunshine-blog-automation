import os
import shutil
import csv
import time
from pathlib import Path
from PIL import Image, ImageFile
import torch
from transformers import CLIPProcessor, CLIPModel
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

ImageFile.LOAD_TRUNCATED_IMAGES = True

# --- ì„¤ì • ---
SOURCE_DIR = '/Users/al02399300/Desktop/Jun_AI/Dog_Contents/project_sunshine/media_bank/photos/01_haetsali_raw'
# "Curated"ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ ë³€ê²½í•˜ì—¬ ìˆ˜ë™ ë¶„ë¥˜ê¸‰ í€„ë¦¬í‹° ì§€í–¥
OUTPUT_BASE = '/Users/al02399300/Desktop/Jun_AI/Dog_Contents/project_sunshine/media_bank/photos/02_haetsali_curated_strict'
CSV_REPORT = '/Users/al02399300/Desktop/Jun_AI/Dog_Contents/project_sunshine/media_bank/strict_classification_report.csv'

# ì„ê³„ê°’ (ì´ ì ìˆ˜ë³´ë‹¤ ë‚®ìœ¼ë©´ 99_unsureë¡œ ë³´ëƒ„)
# CLIP ì ìˆ˜ëŠ” ìƒëŒ€ì ì´ë¯€ë¡œ softmax í›„ í™•ë¥ ê°’ ê¸°ì¤€. í•­ëª©ì´ 13ê°œì´ë¯€ë¡œ í‰ê·  0.07. 
# 0.2 ì´ìƒì´ë©´ ê½¤ í™•ì‹¤í•œ í¸. ì‚¬ìš©ìê°€ ì—„ê²©í•¨ì„ ì›í•˜ë¯€ë¡œ 0.25 ì„¤ì •.
CONFIDENCE_THRESHOLD = 0.25

# ì‹¬ì¸µ ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬ ì •ì˜ (ìƒí˜¸ ë°°íƒ€ì  ë¬˜ì‚¬ ê°•í™”)
DEEP_CATEGORIES = {
    '01_face_closeup': [
        'extreme close up photo of a golden retriever face only',
        'dog face filling the frame, no body visible',
        'headshot of a golden retriever'
    ],
    '02_sitting_pose': [
        'golden retriever dog sitting on the floor upright',
        'dog sitting body posture, not lying down',
        'full body of a sitting dog'
    ],
    '03_standing_pose': [
        'golden retriever dog standing on four legs',
        'side view of a standing dog',
        'dog standing up'
    ],
    '04_lying_down_sleep': [
        'golden retriever lying down on floor',
        'dog sleeping on the ground',
        'dog resting head on paws on floor'
    ],
    '05_lying_down_belly': [
        'dog lying on back showing belly',
        'golden retriever rolling on floor belly up',
        'upside down dog face'
    ],
    '06_action_running': [
        'dog running fast in outdoor',
        'action shot of golden retriever jumping',
        'blur motion of running dog'
    ],
    '07_eating': [
        'dog eating food from a bowl',
        'dog chewing a treat or snack',
        'close up of dog mouth eating'
    ],
    '08_with_human': [
        'human hand petting a dog',
        'dog together with a person',
        'selfie with a dog'
    ],
    '09_tilted_head_curious': [
        'dog tilting head to the side questioning',
        'golden retriever with head tilt curious expression'
    ],
    '10_back_view': [
        'back of the dog head and body',
        'dog looking away from camera',
        'rear view of golden retriever'
    ],
    '99_low_quality': [
        'extremely blurry photo',
        'too dark image, black screen',
        'no dog visible in photo'
    ]
}

def setup_model():
    print("ğŸ”„ ì—„ê²© ëª¨ë“œ ëª¨ë¸ ë¡œë”© ì¤‘... (CLIP ViT-B/32)")
    model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
    processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
    print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ.")
    return model, processor

def classify_single(image_path, model, processor):
    try:
        image = Image.open(image_path).convert('RGB')
    except Exception as e:
        return '99_error', 0.0

    flat_prompts = []
    prompt_to_cat = {}
    for cat, prompts in DEEP_CATEGORIES.items():
        for p in prompts:
            flat_prompts.append(p)
            prompt_to_cat[p] = cat
            
    # CLIP Inference
    inputs = processor(text=flat_prompts, images=image, return_tensors="pt", padding=True)
    
    with torch.no_grad():
        outputs = model(**inputs)
        # softmaxë¡œ í™•ë¥  ë³€í™˜
        probs = outputs.logits_per_image.softmax(dim=1)
        
    best_idx = probs.argmax().item()
    best_prompt = flat_prompts[best_idx]
    category = prompt_to_cat[best_prompt]
    score = probs[0][best_idx].item()
    
    return category, score

def main():
    print("ğŸš€ ì‚¬ì§„ ì •ë°€ ë¶„ë¥˜(Strict Mode) ì‹œì‘")
    print("ğŸ‘‰ ê¸°ì¤€: ìì„¸(ì•‰ê¸°/ëˆ•ê¸°)ì™€ ì•µê¸€(ì–¼êµ´/ì „ì‹ )ì„ ì—„ê²©íˆ êµ¬ë¶„")
    print(f"ğŸ“‚ ì›ë³¸ ì†ŒìŠ¤: {SOURCE_DIR}")
    print(f"ğŸ“‚ ì €ì¥ ìœ„ì¹˜: {OUTPUT_BASE}")
    
    if os.path.exists(OUTPUT_BASE):
        print("âš ï¸ ê¸°ì¡´ ê²°ê³¼ í´ë”ê°€ ìˆì–´ ë®ì–´ì“°ê±°ë‚˜ ì¶”ê°€í•©ë‹ˆë‹¤.")
    
    os.makedirs(OUTPUT_BASE, exist_ok=True)
    model, processor = setup_model()
    
    # ì†ŒìŠ¤ í´ë” íƒìƒ‰
    all_images = []
    source_path = Path(SOURCE_DIR)
    # ì¬ê·€ì ìœ¼ë¡œ íƒìƒ‰í•˜ë˜, ì´ë¯¸ ë¶„ë¥˜ëœ í´ë” ë§ê³  ì›ë³¸(raw)ì´ë‚˜ í•©ì³ì§„ ê³³ì„ ë´ì•¼í•¨.
    # í•˜ì§€ë§Œ ì‚¬ìš©ìê°€ 'media_bank/photos/01_haetsali_raw'ë¡œ ë‹¤ ì˜®ê¸°ë¼ê³  í–ˆì—ˆìŒ.
    for ext in ['*.jpg', '*.jpeg', '*.png', '*.heic', '*.JPG', '*.JPEG', '*.PNG']:
        all_images.extend(list(source_path.rglob(ext)))
        
    total = len(all_images)
    print(f"ğŸ“¸ ì´ ì²˜ë¦¬ ëŒ€ìƒ: {total}ì¥")
    
    csv_data = []
    start_time = time.time()
    
    count_dict = {k:0 for k in DEEP_CATEGORIES.keys()}
    count_dict['99_unsure'] = 0
    count_dict['99_error'] = 0
    
    for i, img_path in enumerate(all_images, 1):
        filename = img_path.name
        
        # ë¶„ë¥˜ ì‹¤í–‰
        cat, score = classify_single(img_path, model, processor)
        
        # ì„ê³„ê°’ ì ìš©: ì ìˆ˜ê°€ ë‚®ìœ¼ë©´ '99_unsure'ë¡œ ë³´ë‚´ì„œ ì‚¬ìš©ìê°€ ì§ì ‘ ë³´ê²Œ í•¨
        if score < CONFIDENCE_THRESHOLD and cat != '99_low_quality':
            final_cat = '99_unsure_mixed'
        else:
            final_cat = cat
            
        # ê²°ê³¼ ë³µì‚¬
        target_dir = Path(OUTPUT_BASE) / final_cat
        target_dir.mkdir(parents=True, exist_ok=True)
        target_file = target_dir / filename
        
        # ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ ì—†ìœ¼ë©´ ë³µì‚¬
        if not target_file.exists():
            try:
                shutil.copy2(img_path, target_file)
            except Exception as e:
                print(f"Copy Error: {e}")
        
        # í†µê³„
        if final_cat in count_dict:
            count_dict[final_cat] += 1
        else:
            count_dict[final_cat] = 1 # unsure ë“±
            
        csv_data.append([filename, final_cat, score, str(img_path)])
        
        if i % 20 == 0:
            elapsed = time.time() - start_time
            print(f"[{i}/{total}] ì²˜ë¦¬ì¤‘... ({final_cat}, {score:.2f})")
            
    # ë¦¬í¬íŠ¸ ì €ì¥
    with open(CSV_REPORT, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow(['filename', 'strict_category', 'score', 'original_path'])
        writer.writerows(csv_data)
        
    print(f"\nâœ… ì •ë°€ ë¶„ë¥˜ ì™„ë£Œ!")
    print("ğŸ“Š ê²°ê³¼ ìš”ì•½:")
    for k, v in count_dict.items():
        print(f"  {k}: {v}ì¥")
    print(f"ğŸ“‚ ê²°ê³¼ í´ë”: {OUTPUT_BASE}")

if __name__ == "__main__":
    main()
