#!/usr/bin/env python3
"""
ì»¤ë²„ ì´ë¯¸ì§€ ê´€ë¦¬ ìŠ¤í¬ë¦½íŠ¸
- 03_cover_sources â†’ 02_ready ì´ë™ + ì†ŒìŠ¤ ìë™ ì‚­ì œ
- 02_ready â†’ 01_published ì´ë™ (ê²Œì‹œ ì™„ë£Œ ì‹œ)
- ë ˆë”” ì´ë™ ì‹œ Google Sheets ìë™ ë™ê¸°í™”

ì‚¬ìš©ë²•:
    # ì†ŒìŠ¤ì—ì„œ ë ˆë””ë¡œ ì´ë™ (ì†ŒìŠ¤ ìë™ ì‚­ì œ + ì‹œíŠ¸ ë™ê¸°í™”)
    python cover_manager.py move <source_filename> <topic_en> <topic_kr> [--number 123]

    # ì†ŒìŠ¤ í´ë” ì •ë¦¬ (ì´ë¯¸ ë ˆë””ì— ìˆëŠ” í•­ëª© ì‚­ì œ)
    python cover_manager.py cleanup

    # í˜„í™© í™•ì¸
    python cover_manager.py status
"""

import os
import sys
import json
import shutil
import argparse
from pathlib import Path
from datetime import datetime

# ê²½ë¡œ ì„¤ì •
PROJECT_ROOT = Path(__file__).parent.parent.parent
COVER_BASE = PROJECT_ROOT / "content" / "images" / "000_cover"
SOURCE_DIR = COVER_BASE / "03_cover_sources"
READY_DIR = COVER_BASE / "02_ready"
PUBLISHED_DIR = COVER_BASE / "01_published"
MAPPING_FILE = SOURCE_DIR / "cover_mapping.json"

# Google Sheets ë™ê¸°í™” ëª¨ë“ˆ ì„í¬íŠ¸
sys.path.insert(0, str(PROJECT_ROOT))
try:
    from core.utils.google_sheets_manager import ContentSheetManager
    SHEETS_AVAILABLE = True
except ImportError:
    SHEETS_AVAILABLE = False
    print("âš ï¸ Google Sheets ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨ - ë¡œì»¬ ëª¨ë“œë¡œ ì‹¤í–‰")


def normalize_topic_name(name: str) -> str:
    """ì˜ë¬¸ëª… ì •ê·œí™” (ìˆ«ì ì ‘ë¯¸ì‚¬ ì œê±°, ì†Œë¬¸ì)"""
    return name.lower().rstrip('0123456789').strip('_')


def check_sheet_duplicate(topic_en: str, topic_kr: str) -> bool:
    """
    Google Sheetsì—ì„œ ì¤‘ë³µ í™•ì¸ (ì •ê·œí™”ëœ ì´ë¦„ + í•œê¸€ëª… ê¸°ì¤€)

    Returns:
        True if duplicate exists
    """
    if not SHEETS_AVAILABLE:
        return False

    try:
        manager = ContentSheetManager()
        if not manager.connect():
            return False

        contents = manager.get_all_contents()
        normalized_input = normalize_topic_name(topic_en)

        for c in contents:
            existing_en = c.get('ì˜ë¬¸ëª…', '')
            existing_kr = c.get('í•œê¸€ëª…', '')
            normalized_existing = normalize_topic_name(existing_en)

            # ì •ê·œí™”ëœ ì˜ë¬¸ëª… ë˜ëŠ” í•œê¸€ëª…ì´ ì¼ì¹˜í•˜ë©´ ì¤‘ë³µ
            if normalized_input == normalized_existing:
                print(f"âš ï¸ ì‹œíŠ¸ ì¤‘ë³µ: {topic_en} â†” {existing_en} ({existing_kr})")
                return True
            if topic_kr == existing_kr:
                print(f"âš ï¸ ì‹œíŠ¸ ì¤‘ë³µ (í•œê¸€ëª…): {topic_kr} â†” {existing_en}")
                return True

        return False
    except:
        return False


def sync_to_sheets(number: int, topic_en: str, topic_kr: str, safety: str = 'SAFE') -> bool:
    """
    Google Sheetsì— ì»¤ë²„ ì •ë³´ ë™ê¸°í™”

    Args:
        number: ì»¤ë²„ ë²ˆí˜¸
        topic_en: ì˜ë¬¸ ì£¼ì œëª…
        topic_kr: í•œê¸€ ì£¼ì œëª…
        safety: ì•ˆì „ë„ (SAFE/CAUTION/DANGER)

    Returns:
        ì„±ê³µ ì—¬ë¶€
    """
    if not SHEETS_AVAILABLE:
        print("âš ï¸ Google Sheets ë™ê¸°í™” ìŠ¤í‚µ (ëª¨ë“ˆ ë¯¸ë¡œë“œ)")
        return False

    try:
        manager = ContentSheetManager()

        # ì—°ê²° ì‹œë„
        if not manager.connect():
            print("âš ï¸ Google Sheets ì—°ê²° ì‹¤íŒ¨ - ë¡œì»¬ ìºì‹œì—ë§Œ ì €ì¥")
            return False

        # ğŸ”’ ì¤‘ë³µ ì²´í¬ (ì •ê·œí™” + í•œê¸€ëª…)
        if check_sheet_duplicate(topic_en, topic_kr):
            print(f"âŒ ì‹œíŠ¸ ë™ê¸°í™” ìŠ¤í‚µ: ì¤‘ë³µ í•­ëª© ì¡´ì¬")
            return False

        # ì‹œíŠ¸ì— ì¶”ê°€ (í‘œì§€ëŒ€ê¸° ìƒíƒœë¡œ)
        success = manager.add_content(
            number=f"{number:03d}",
            topic_en=topic_en,
            topic_kr=topic_kr,
            safety=safety,
            status='í‘œì§€ëŒ€ê¸°',
            publish_date=None,
            instagram_url=''
        )

        if success:
            print(f"ğŸ“Š Google Sheets ë™ê¸°í™” ì™„ë£Œ: {topic_kr} ({topic_en})")

        return success

    except Exception as e:
        print(f"âŒ Google Sheets ë™ê¸°í™” ì‹¤íŒ¨: {e}")
        return False


def load_mapping() -> dict:
    """ë§¤í•‘ íŒŒì¼ ë¡œë“œ"""
    if MAPPING_FILE.exists():
        with open(MAPPING_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {"description": "ì»¤ë²„ ì´ë¯¸ì§€ ë§¤í•‘", "mappings": {}, "processed": []}


def save_mapping(mapping: dict):
    """ë§¤í•‘ íŒŒì¼ ì €ì¥"""
    mapping['last_updated'] = datetime.now().isoformat()
    with open(MAPPING_FILE, 'w', encoding='utf-8') as f:
        json.dump(mapping, f, ensure_ascii=False, indent=2)


def get_next_cover_number() -> int:
    """ë‹¤ìŒ ì»¤ë²„ ë²ˆí˜¸ ê³„ì‚°"""
    max_num = 0
    for f in READY_DIR.glob("cover_*.png"):
        try:
            parts = f.stem.split('_')
            if len(parts) >= 2:
                num = int(parts[1])
                max_num = max(max_num, num)
        except (ValueError, IndexError):
            continue

    for f in PUBLISHED_DIR.glob("cover_*.png"):
        try:
            parts = f.stem.split('_')
            if len(parts) >= 2:
                num = int(parts[1])
                max_num = max(max_num, num)
        except (ValueError, IndexError):
            continue

    return max_num + 1


def check_duplicate(topic_en: str) -> list:
    """
    ë ˆë””/í¼ë¸”ë¦¬ì‹œ í´ë”ì—ì„œ ì¤‘ë³µ í™•ì¸

    Returns:
        ì¤‘ë³µ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ (ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸)
    """
    duplicates = []
    topic_lower = topic_en.lower()

    # ë ˆë”” í´ë” í™•ì¸
    for f in READY_DIR.glob("cover_*.png"):
        parts = f.stem.split('_')
        if len(parts) >= 4:
            existing_topic = parts[-1].lower()
            # DANGER ì ‘ë¯¸ì‚¬ ì²˜ë¦¬
            if existing_topic in ['danger', 'danger2']:
                existing_topic = parts[-2].lower()
            if existing_topic == topic_lower:
                duplicates.append(f)

    # í¼ë¸”ë¦¬ì‹œ í´ë” í™•ì¸
    for f in PUBLISHED_DIR.glob("cover_*.png"):
        parts = f.stem.split('_')
        if len(parts) >= 4:
            existing_topic = parts[-1].lower()
            if existing_topic in ['danger', 'danger2']:
                existing_topic = parts[-2].lower()
            if existing_topic == topic_lower:
                duplicates.append(f)

    return duplicates


def move_to_ready(source_filename: str, topic_en: str, topic_kr: str, number: int = None) -> bool:
    """
    ì†ŒìŠ¤ì—ì„œ ë ˆë””ë¡œ ì´ë™ + ì†ŒìŠ¤ ì‚­ì œ

    Args:
        source_filename: ì†ŒìŠ¤ íŒŒì¼ëª… (hf_xxx.png)
        topic_en: ì˜ë¬¸ ì£¼ì œëª…
        topic_kr: í•œê¸€ ì£¼ì œëª…
        number: ì»¤ë²„ ë²ˆí˜¸ (ì—†ìœ¼ë©´ ìë™ ê³„ì‚°)

    Returns:
        ì„±ê³µ ì—¬ë¶€
    """
    source_path = SOURCE_DIR / source_filename

    if not source_path.exists():
        print(f"âŒ ì†ŒìŠ¤ íŒŒì¼ ì—†ìŒ: {source_filename}")
        return False

    # ğŸ”’ ì¤‘ë³µ ì²´í¬ (ë¨¼ì € ìˆëŠ” íŒŒì¼ ìš°ì„ )
    duplicates = check_duplicate(topic_en)
    if duplicates:
        print(f"âš ï¸ ì¤‘ë³µ ë°œê²¬! '{topic_en}' ì´ë¯¸ ì¡´ì¬:")
        for dup in duplicates:
            print(f"   - {dup.name}")
        print(f"âŒ ì´ë™ ì·¨ì†Œ. ê¸°ì¡´ íŒŒì¼ ìš°ì„  ì •ì±….")
        return False

    # ë²ˆí˜¸ ê³„ì‚°
    if number is None:
        number = get_next_cover_number()

    # ëŒ€ìƒ íŒŒì¼ëª…: cover_{ë²ˆí˜¸}_{í•œê¸€ëª…}_{ì˜ë¬¸ëª…}.png
    target_filename = f"cover_{number}_{topic_kr}_{topic_en}.png"
    target_path = READY_DIR / target_filename

    # ì´ë™ (ë³µì‚¬ í›„ ì‚­ì œ)
    try:
        shutil.copy2(source_path, target_path)
        print(f"âœ… ë³µì‚¬ ì™„ë£Œ: {target_filename}")

        # ì†ŒìŠ¤ ì‚­ì œ
        source_path.unlink()
        print(f"ğŸ—‘ï¸  ì†ŒìŠ¤ ì‚­ì œ: {source_filename}")

        # ë§¤í•‘ ì—…ë°ì´íŠ¸
        mapping = load_mapping()
        if source_filename in mapping.get('mappings', {}):
            del mapping['mappings'][source_filename]

        mapping.setdefault('processed', []).append({
            'source': source_filename,
            'target': target_filename,
            'topic_en': topic_en,
            'topic_kr': topic_kr,
            'date': datetime.now().strftime('%Y-%m-%d')
        })
        save_mapping(mapping)

        # ğŸ”¥ Google Sheets ìë™ ë™ê¸°í™” (ë ˆë”” ì´ë™ ì‹œ ì¦‰ì‹œ)
        sync_to_sheets(number, topic_en, topic_kr)

        return True

    except Exception as e:
        print(f"âŒ ì´ë™ ì‹¤íŒ¨: {e}")
        return False


def cleanup_sources() -> int:
    """ë ˆë””ì— ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ì†ŒìŠ¤ íŒŒì¼ ì‚­ì œ"""
    mapping = load_mapping()

    # ë ˆë”” í´ë”ì˜ topic_en ëª©ë¡
    ready_topics = set()
    for f in READY_DIR.glob("cover_*.png"):
        parts = f.stem.split('_')
        if len(parts) >= 4:
            ready_topics.add(parts[-1].lower())

    deleted = 0
    to_delete = []

    for source_file, info in list(mapping.get('mappings', {}).items()):
        topic_en = info.get('topic_en', '').lower()
        source_path = SOURCE_DIR / source_file

        if topic_en in ready_topics and source_path.exists():
            to_delete.append((source_file, info.get('topic_kr', ''), source_path))

    if not to_delete:
        print("âœ… ì •ë¦¬í•  íŒŒì¼ ì—†ìŒ")
        return 0

    print(f"ğŸ—‘ï¸  {len(to_delete)}ê±´ ì‚­ì œ ì˜ˆì •:")
    for source_file, topic_kr, source_path in to_delete:
        print(f"  - {topic_kr} ({source_file[:40]}...)")
        source_path.unlink()

        # ë§¤í•‘ì—ì„œ ì œê±°
        if source_file in mapping.get('mappings', {}):
            del mapping['mappings'][source_file]

        deleted += 1

    save_mapping(mapping)
    print(f"\nâœ… {deleted}ê±´ ì‚­ì œ ì™„ë£Œ")
    return deleted


def show_status():
    """í˜„í™© í‘œì‹œ"""
    mapping = load_mapping()

    source_files = list(SOURCE_DIR.glob("hf_*.png"))
    ready_files = list(READY_DIR.glob("cover_*.png"))
    published_files = list(PUBLISHED_DIR.glob("cover_*.png"))

    print("=" * 60)
    print("ğŸ“Š ì»¤ë²„ ì´ë¯¸ì§€ í˜„í™©")
    print("=" * 60)
    print(f"  03_cover_sources: {len(source_files)}ê±´")
    print(f"  02_ready:         {len(ready_files)}ê±´")
    print(f"  01_published:     {len(published_files)}ê±´")
    print()

    if source_files:
        print("ğŸ“ ì†ŒìŠ¤ íŒŒì¼ (ë¯¸ì²˜ë¦¬):")
        for f in source_files[:10]:
            info = mapping.get('mappings', {}).get(f.name, {})
            topic_kr = info.get('topic_kr', 'ë¯¸ì§€ì •')
            print(f"  - {topic_kr}: {f.name[:45]}...")
        if len(source_files) > 10:
            print(f"  ... ì™¸ {len(source_files) - 10}ê±´")

    print("=" * 60)


def batch_move_all():
    """ëª¨ë“  ì†ŒìŠ¤ íŒŒì¼ì„ ë ˆë””ë¡œ ì´ë™ (ë§¤í•‘ ì •ë³´ ì‚¬ìš©)"""
    mapping = load_mapping()

    moved = 0
    for source_file, info in list(mapping.get('mappings', {}).items()):
        source_path = SOURCE_DIR / source_file
        if not source_path.exists():
            continue

        topic_en = info.get('topic_en', '')
        topic_kr = info.get('topic_kr', '')

        if not topic_en or not topic_kr:
            print(f"âš ï¸  ë§¤í•‘ ì •ë³´ ë¶ˆì™„ì „: {source_file}")
            continue

        if move_to_ready(source_file, topic_en, topic_kr):
            moved += 1

    print(f"\nâœ… ì´ {moved}ê±´ ì´ë™ ì™„ë£Œ")
    return moved


def sync_ready_to_sheets():
    """
    ë ˆë”” í´ë”ì˜ ëª¨ë“  ì»¤ë²„ë¥¼ Google Sheetsì— ë™ê¸°í™”
    (ê¸°ì¡´ í•­ëª©ì€ ìŠ¤í‚µ)
    """
    if not SHEETS_AVAILABLE:
        print("âŒ Google Sheets ëª¨ë“ˆ ë¯¸ë¡œë“œ")
        return 0

    try:
        manager = ContentSheetManager()
        if not manager.connect():
            print("âŒ Google Sheets ì—°ê²° ì‹¤íŒ¨")
            return 0

        # ê¸°ì¡´ ì‹œíŠ¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        existing = {c.get('ì˜ë¬¸ëª…', '').lower() for c in manager.get_all_contents()}

        synced = 0
        skipped = 0

        for f in READY_DIR.glob("cover_*.png"):
            # cover_{ë²ˆí˜¸}_{í•œê¸€ëª…}_{ì˜ë¬¸ëª…}.png íŒŒì‹±
            parts = f.stem.split('_')
            if len(parts) < 4:
                continue

            try:
                number = int(parts[1])
                topic_kr = parts[2]
                topic_en = parts[-1].lower()

                # DANGER íŒŒì¼ ê°ì§€
                safety = 'SAFE'
                if 'DANGER' in f.stem.upper():
                    safety = 'DANGER'
                    topic_en = parts[-2].lower()  # DANGER ì•ì˜ ì˜ë¬¸ëª…

                # ì´ë¯¸ ì¡´ì¬í•˜ë©´ ìŠ¤í‚µ
                if topic_en in existing:
                    skipped += 1
                    continue

                # ì‹œíŠ¸ì— ì¶”ê°€
                success = manager.add_content(
                    number=f"{number:03d}",
                    topic_en=topic_en,
                    topic_kr=topic_kr,
                    safety=safety,
                    status='í‘œì§€ëŒ€ê¸°',
                    publish_date=None,
                    instagram_url=''
                )

                if success:
                    synced += 1
                    print(f"  âœ… {topic_kr} ({topic_en})")

            except (ValueError, IndexError) as e:
                print(f"  âš ï¸ íŒŒì‹± ì‹¤íŒ¨: {f.name} - {e}")
                continue

        print(f"\nğŸ“Š ë™ê¸°í™” ê²°ê³¼: ì¶”ê°€ {synced}ê±´, ìŠ¤í‚µ {skipped}ê±´ (ì´ë¯¸ ì¡´ì¬)")
        return synced

    except Exception as e:
        print(f"âŒ ë™ê¸°í™” ì‹¤íŒ¨: {e}")
        return 0


def main():
    parser = argparse.ArgumentParser(description='ì»¤ë²„ ì´ë¯¸ì§€ ê´€ë¦¬')
    subparsers = parser.add_subparsers(dest='command', help='ëª…ë ¹')

    # move ëª…ë ¹
    move_parser = subparsers.add_parser('move', help='ì†ŒìŠ¤ì—ì„œ ë ˆë””ë¡œ ì´ë™')
    move_parser.add_argument('source', help='ì†ŒìŠ¤ íŒŒì¼ëª…')
    move_parser.add_argument('topic_en', help='ì˜ë¬¸ ì£¼ì œëª…')
    move_parser.add_argument('topic_kr', help='í•œê¸€ ì£¼ì œëª…')
    move_parser.add_argument('--number', type=int, help='ì»¤ë²„ ë²ˆí˜¸')

    # cleanup ëª…ë ¹
    subparsers.add_parser('cleanup', help='ì†ŒìŠ¤ í´ë” ì •ë¦¬')

    # status ëª…ë ¹
    subparsers.add_parser('status', help='í˜„í™© í™•ì¸')

    # batch ëª…ë ¹
    subparsers.add_parser('batch', help='ëª¨ë“  ì†ŒìŠ¤ íŒŒì¼ ì´ë™')

    # sync ëª…ë ¹ (ë ˆë”” â†’ êµ¬ê¸€ì‹œíŠ¸)
    subparsers.add_parser('sync', help='ë ˆë”” í´ë” â†’ Google Sheets ë™ê¸°í™”')

    args = parser.parse_args()

    if args.command == 'move':
        move_to_ready(args.source, args.topic_en, args.topic_kr, args.number)
    elif args.command == 'cleanup':
        cleanup_sources()
    elif args.command == 'status':
        show_status()
    elif args.command == 'batch':
        batch_move_all()
    elif args.command == 'sync':
        sync_ready_to_sheets()
    else:
        parser.print_help()


if __name__ == '__main__':
    main()
