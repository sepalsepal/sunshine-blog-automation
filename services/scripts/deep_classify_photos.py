import os
import shutil
import csv
import time
from pathlib import Path
from PIL import Image, ImageFile
import torch
from transformers import CLIPProcessor, CLIPModel
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# ì´ë¯¸ì§€ ë¡œë”© ì„¤ì •
ImageFile.LOAD_TRUNCATED_IMAGES = True

# --- ì„¤ì • ---
# ì´ë¯¸ media_bank/photos/01_haetsali_raw ë¡œ ì´ë™ëœ ìƒíƒœë¼ê³  ê°€ì •
SOURCE_DIR = '/Users/al02399300/Desktop/Jun_AI/Dog_Contents/project_sunshine/media_bank/photos/01_haetsali_raw'
# ìƒˆë¡œìš´ ë¶„ë¥˜ ê²°ê³¼ ì €ì¥ì†Œ
OUTPUT_BASE = '/Users/al02399300/Desktop/Jun_AI/Dog_Contents/project_sunshine/media_bank/photos/02_haetsali_deep_sorted'
CSV_REPORT = '/Users/al02399300/Desktop/Jun_AI/Dog_Contents/project_sunshine/media_bank/deep_classification_report.csv'

# ì‹¬ì¸µ ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬ ì •ì˜
DEEP_CATEGORIES = {
    '01_smile_face': [
        'close up photo of a golden retriever face smiling',
        'dog face closeup happy expression',
        'golden retriever headshot smiling'
    ],
    '02_smile_body_sit': [
        'golden retriever sitting and smiling',
        'dog sitting on floor happy',
        'full body shot of dog sitting'
    ],
    '03_smile_body_stand': [
        'golden retriever standing and smiling',
        'dog standing up happy'
    ],
    '04_action_run': [
        'dog running fast',
        'golden retriever jumping or running',
        'action shot of dog moving'
    ],
    '05_sleeping': [
        'dog sleeping with eyes closed',
        'golden retriever lying down sleeping',
        'sleeping dog on floor',
        'peaceful dog resting eyes shut'
    ],
    '06_curious_tilt': [
        'dog tilting head sideways',
        'curious dog looking at camera',
        'golden retriever head tilt'
    ],
    '07_eating': [
        'dog eating food from bowl',
        'dog chewing on a treat',
        'golden retriever eating'
    ],
    '08_with_human': [
        'dog together with a human',
        'person petting golden retriever',
        'dog being hugged by human',
        'human hand touching dog'
    ],
    '09_profile_side': [
        'side profile view of golden retriever',
        'dog looking to the side'
    ],
    '10_back_view': [
        'back of the dog',
        'dog looking away from camera',
        'rear view of golden retriever'
    ],
    '11_outdoor_scenery': [
        'dog in a beautiful outdoor landscape',
        'dog on grass field far away',
        'scenic photo with dog'
    ],
    '99_low_quality': [
        'blurry blurry photo',
        'very dark image',
        'out of focus dog',
        'bad quality noise'
    ]
}

def setup_model():
    print("ğŸ”„ ëª¨ë¸ ë¡œë”© ì¤‘... (CLIP ViT-B/32)")
    model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
    processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
    print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ.")
    return model, processor

def classify_single(image_path, model, processor):
    try:
        image = Image.open(image_path).convert('RGB')
    except Exception as e:
        return '99_error', 0.0

    flat_prompts = []
    prompt_to_cat = {}
    for cat, prompts in DEEP_CATEGORIES.items():
        for p in prompts:
            flat_prompts.append(p)
            prompt_to_cat[p] = cat
            
    inputs = processor(text=flat_prompts, images=image, return_tensors="pt", padding=True)
    
    with torch.no_grad():
        outputs = model(**inputs)
        probs = outputs.logits_per_image.softmax(dim=1)
        
    best_idx = probs.argmax().item()
    best_prompt = flat_prompts[best_idx]
    category = prompt_to_cat[best_prompt]
    score = probs[0][best_idx].item()
    
    # ì„ê³„ê°’ ì ìš© (ë„ˆë¬´ ë‚®ìœ¼ë©´ ê¸°íƒ€ë¡œ ë¶„ë¥˜ ê°€ëŠ¥í•˜ì§€ë§Œ, ì¼ë‹¨ ê°€ì¥ ë†’ì€ ê²ƒ ì„ íƒ)
    return category, score

def main():
    print("ğŸš€ ì‹¬ì¸µ ë¶„ë¥˜(Deep Classification) ì‹œì‘")
    print(f"ğŸ“‚ ì›ë³¸ ì†ŒìŠ¤: {SOURCE_DIR}")
    print(f"ğŸ“‚ ì €ì¥ ìœ„ì¹˜: {OUTPUT_BASE}")
    
    os.makedirs(OUTPUT_BASE, exist_ok=True)
    model, processor = setup_model()
    
    # ì†ŒìŠ¤ í´ë” ë‚´ì˜ ëª¨ë“  ì´ë¯¸ì§€ ì¬ê·€ íƒìƒ‰
    all_images = []
    source_path = Path(SOURCE_DIR)
    for ext in ['*.jpg', '*.jpeg', '*.png', '*.heic', '*.JPG', '*.JPEG', '*.PNG']:
        all_images.extend(list(source_path.rglob(ext)))
        
    total = len(all_images)
    print(f"ğŸ“¸ ì´ ë¶„ë¥˜ ëŒ€ìƒ: {total}ì¥")
    
    csv_data = []
    start_time = time.time()
    
    for i, img_path in enumerate(all_images, 1):
        filename = img_path.name
        
        # ë¶„ë¥˜ ì‹¤í–‰
        cat, score = classify_single(img_path, model, processor)
        
        # ê²°ê³¼ í´ë”ë¡œ ë³µì‚¬ (ì´ë™ ì•„ë‹˜, ì•ˆì „í•˜ê²Œ ë³µì‚¬)
        # íŒŒì¼ëª… ì¶©ëŒ ë°©ì§€: ì›ë˜ í´ë”ëª…_íŒŒì¼ëª…
        parent_folder = img_path.parent.name
        new_filename = f"{parent_folder}_{filename}" if parent_folder != '01_haetsali_raw' else filename
        # ë˜ëŠ” ê·¸ëƒ¥ ê³ ìœ í•˜ê²Œ ìœ ì§€. ì¼ë‹¨ ë®ì–´ì“°ê¸° ë°©ì§€ìš© prefix
        
        target_dir = Path(OUTPUT_BASE) / cat
        target_dir.mkdir(parents=True, exist_ok=True)
        target_file = target_dir / filename
        
        if not target_file.exists():
            try:
                shutil.copy2(img_path, target_file)
            except Exception as e:
                print(f"Copy Error: {e}")
        
        csv_data.append([filename, cat, score, str(img_path)])
        
        if i % 20 == 0:
            elapsed = time.time() - start_time
            print(f"[{i}/{total}] ë¶„ë¥˜ì¤‘... ({cat})")
            
    # ë¦¬í¬íŠ¸ ì €ì¥
    with open(CSV_REPORT, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow(['filename', 'deep_category', 'score', 'original_path'])
        writer.writerows(csv_data)
        
    print(f"\nâœ… ì‹¬ì¸µ ë¶„ë¥˜ ì™„ë£Œ! ê²°ê³¼: {OUTPUT_BASE}")
    print(f"ğŸ“„ ë¦¬í¬íŠ¸: {CSV_REPORT}")

if __name__ == "__main__":
    main()
