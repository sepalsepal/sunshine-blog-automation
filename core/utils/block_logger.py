#!/usr/bin/env python3
"""
Block Logger - ì‹¤íŒ¨/ì°¨ë‹¨ ë¡œê·¸ ê¸°ë¡ ìœ í‹¸ë¦¬í‹°
BLOCK_LOG_SCHEMA.json í˜•ì‹ ì¤€ìˆ˜
"""

import json
from pathlib import Path
from datetime import datetime

PROJECT_ROOT = Path(__file__).parent.parent.parent
BLOCK_LOG_DIR = PROJECT_ROOT / "config/logs/blocks"


def log_block(
    reason_code: str,
    food_id: str = None,
    detected_by: str = "unknown",
    reason_detail: str = None,
    rule_name: str = None,
    rule_version: str = None,
    recovery_action: str = "none",
    retry_count: int = 0
) -> dict:
    """
    ì°¨ë‹¨/ì‹¤íŒ¨ ë¡œê·¸ ê¸°ë¡

    Args:
        reason_code: ì°¨ë‹¨ ì‚¬ìœ  ì½”ë“œ (BLOCK_LOG_SCHEMA ì°¸ì¡°)
        food_id: ì½˜í…ì¸  ì‹ë³„ì
        detected_by: ì°¨ë‹¨ì„ ê°ì§€í•œ ëª¨ë“ˆ
        reason_detail: ìƒì„¸ ì„¤ëª…
        rule_name: ì ìš©ëœ ê·œì¹™ ì´ë¦„
        rule_version: ì ìš©ëœ ê·œì¹™ ë²„ì „
        recovery_action: ë³µêµ¬ ì¡°ì¹˜ (auto_retry, regenerate, manual_fix, skip, none)
        retry_count: ì¬ì‹œë„ íšŸìˆ˜

    Returns:
        ê¸°ë¡ëœ ë¡œê·¸ ê°ì²´
    """
    BLOCK_LOG_DIR.mkdir(parents=True, exist_ok=True)

    log_entry = {
        "blocked": True,
        "reason_code": reason_code,
        "reason_detail": reason_detail,
        "food_id": food_id,
        "rule_name": rule_name,
        "rule_version": rule_version,
        "detected_by": detected_by,
        "timestamp": datetime.now().isoformat(),
        "recovery_action": recovery_action,
        "recovery_status": "pending",
        "retry_count": retry_count
    }

    # íŒŒì¼ì— ê¸°ë¡
    log_file = BLOCK_LOG_DIR / f"block_{datetime.now().strftime('%Y%m%d')}.jsonl"
    with open(log_file, 'a', encoding='utf-8') as f:
        f.write(json.dumps(log_entry, ensure_ascii=False) + '\n')

    print(f"ğŸš« BLOCK: {reason_code} - {food_id or 'unknown'}")
    return log_entry


def get_recent_blocks(limit: int = 10) -> list:
    """ìµœê·¼ ì°¨ë‹¨ ë¡œê·¸ ì¡°íšŒ"""
    if not BLOCK_LOG_DIR.exists():
        return []

    blocks = []
    for log_file in sorted(BLOCK_LOG_DIR.glob("block_*.jsonl"), reverse=True):
        with open(log_file, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    blocks.append(json.loads(line))
                    if len(blocks) >= limit:
                        return blocks
    return blocks


def get_blocks_by_food(food_id: str) -> list:
    """íŠ¹ì • ìŒì‹ì˜ ì°¨ë‹¨ ì´ë ¥ ì¡°íšŒ"""
    if not BLOCK_LOG_DIR.exists():
        return []

    blocks = []
    for log_file in BLOCK_LOG_DIR.glob("block_*.jsonl"):
        with open(log_file, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    entry = json.loads(line)
                    if entry.get("food_id") == food_id:
                        blocks.append(entry)
    return blocks


# í¸ì˜ í•¨ìˆ˜ë“¤
def block_missing_metadata(food_id: str, field: str, detected_by: str = "pre_check"):
    return log_block(
        reason_code="MISSING_METADATA",
        food_id=food_id,
        detected_by=detected_by,
        reason_detail=f"í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {field}",
        recovery_action="regenerate"
    )


def block_rule_mismatch(food_id: str, expected: str, actual: str, detected_by: str = "verifier"):
    return log_block(
        reason_code="RULE_MISMATCH",
        food_id=food_id,
        detected_by=detected_by,
        reason_detail=f"ê·œì¹™ ë¶ˆì¼ì¹˜: ê¸°ëŒ€ {expected}, ì‹¤ì œ {actual}",
        recovery_action="regenerate"
    )


def block_pd_not_approved(food_id: str):
    return log_block(
        reason_code="PD_NOT_APPROVED",
        food_id=food_id,
        detected_by="publish_gate",
        reason_detail="PD ìŠ¹ì¸ ì—†ì´ ê²Œì‹œ ì‹œë„",
        recovery_action="none"
    )


def block_pd_rejected(food_id: str, reason: str):
    return log_block(
        reason_code="PD_REJECTED",
        food_id=food_id,
        detected_by="pd_approval",
        reason_detail=f"PD ë°˜ë ¤: {reason}",
        recovery_action="regenerate"
    )
